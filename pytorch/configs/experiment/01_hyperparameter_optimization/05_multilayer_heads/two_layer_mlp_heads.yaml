# @package _global_

# Copyright 2025 Thousand Brains Project
#
# Copyright may exist in Contributors' modifications
# and/or contributions to the work.
#
# Use of this source code is governed by the MIT
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.

# Configuration for testing TwoLayerMLPHead (Linear + GELU + Dropout + Linear)

defaults:
  - /experiment/01_hyperparameter_optimization/starting_config
  - _self_

model:
  net:
    classification_head_type: "two_layer_mlp"
    quaternion_head_type: "two_layer_mlp"

trainer:
  gradient_clip_val: 1.0 # Added following 02_gradient_clipping experiment

data:
  train_transform:
    _target_: src.data.transforms.rgbd_transforms.RGBDTrainAugment

logger:
  wandb:
    name: "vit-b16_two_layer_mlp_heads"
