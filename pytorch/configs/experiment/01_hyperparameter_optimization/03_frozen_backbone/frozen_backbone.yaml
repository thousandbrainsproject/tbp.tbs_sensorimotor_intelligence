# @package _global_

defaults:
  - /experiment/hyperparameter_optimization/starting_config
  - _self_

trainer:
  gradient_clip_val: 1.0 # Added following 02_gradient_clipping experiment

model:
  net:
    freeze_backbone: true

logger:
  wandb:
    name: "vit-b16_frozen_backbone"
